{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo: XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, nombrefeat, nombretarget):\n",
    "        \n",
    "    temp = train.groupby(nombrefeat)[nombretarget].transform(np.mean) #Saco promedio\n",
    "    temp = preprocessing.scale(temp) #Normalizo\n",
    "    train[nombrefeat + \"_mean\"] = temp #Dejo en el DF\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_decoding(x_test, nombrefeat, x_train):\n",
    "    \n",
    "    nombrefeatmean = nombrefeat + \"_mean\"\n",
    "    \n",
    "    temp = x_train.loc[:,[nombrefeat,nombrefeatmean]]\n",
    "    temp = temp.set_index(nombrefeat)\n",
    "    temp = temp.drop_duplicates()\n",
    "    temp = temp.T.squeeze()\n",
    "    values = x_test[nombrefeat].map(temp)\n",
    "    x_test[nombrefeatmean] = values \n",
    "\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "x_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### FEATURES DE TRAIN ################\n",
    "\n",
    "\n",
    "train = train.drop(['descripcion', 'titulo', 'direccion', 'fecha', 'id', 'antiguedad',\n",
    "                    'lng', 'tipodepropiedad'], axis = 1)\n",
    "\n",
    "#Adiciono servicios\n",
    "train['servicios'] = train['piscina'] + train['gimnasio'] + train['usosmultiples']\n",
    "\n",
    "#Elimino los residuos\n",
    "train = train.drop(['piscina', 'gimnasio','usosmultiples','escuelascercanas', \n",
    "                    'centroscomercialescercanos'], axis = 1)\n",
    "\n",
    "y_train = train['precio']\n",
    "temporal = train\n",
    "\n",
    "#Calculo los mean target\n",
    "x_train = mean_target_encoding(train, \"provincia\", \"precio\")\n",
    "x_train['precio'] = y_train\n",
    "x_train = mean_target_encoding(x_train, \"ciudad\", \"precio\")\n",
    "\n",
    "########### FEATURES DE TEST ################\n",
    "\n",
    "#Adiciono servicios\n",
    "x_test['servicios'] = x_test['piscina'] + x_test['gimnasio'] + x_test['usosmultiples']\n",
    "\n",
    "#Se los asigno a los test (NO LOS CALCULO CON ELLOS!!!!!!)\n",
    "x_test = mean_target_decoding(x_test, \"provincia\", temporal)\n",
    "x_test = mean_target_decoding(x_test, \"ciudad\", temporal)\n",
    "\n",
    "#Elimino los residuos\n",
    "x_test = x_test.drop(['piscina', 'gimnasio','usosmultiples','escuelascercanas', 'fecha',\n",
    "                  'centroscomercialescercanos', 'titulo', 'direccion', 'descripcion',\n",
    "                  'id', 'antiguedad', 'lng','tipodepropiedad'], axis = 1)\n",
    "\n",
    "########### LIMPIO LOS QUE HICE MEAN ################\n",
    "\n",
    "x_train.drop([\"precio\",\"provincia\", \"ciudad\"], axis=1, inplace = True)\n",
    "x_test.drop([\"provincia\", \"ciudad\"], axis=1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(base_score=0.5, \n",
    "                             booster='gbtree', \n",
    "                             colsample_bylevel=1,\n",
    "                             colsample_bynode=1, \n",
    "                             colsample_bytree=0.7, \n",
    "                             gamma=0.2,\n",
    "                             importance_type='gain', \n",
    "                             learning_rate=0.1, \n",
    "                             max_delta_step=0,\n",
    "                             max_depth=8, \n",
    "                             min_child_weight=3, \n",
    "                             missing=None, \n",
    "                             n_estimators=250,\n",
    "                             n_jobs=1, \n",
    "                             nthread=-1, \n",
    "                             objective='reg:linear', \n",
    "                             random_state=0,\n",
    "                             reg_alpha=0, \n",
    "                             reg_lambda=1, \n",
    "                             scale_pos_weight=1, \n",
    "                             seed=None,\n",
    "                             silent=None, \n",
    "                             subsample=0.7, \n",
    "                             verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ailen-magali/.local/lib/python3.5/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/ailen-magali/.local/lib/python3.5/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "#Fitteo\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.50774515500234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predigo\n",
    "prediccion = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.read_csv(\"test.csv\")\n",
    "predicciones = test_original.loc[:, ['id','ciudad']]\n",
    "predicciones.rename(columns = {'ciudad' : 'target'}, inplace = True)\n",
    "predicciones['target'] = prediccion\n",
    "predicciones = predicciones.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv(r'prediccionXGB7.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
