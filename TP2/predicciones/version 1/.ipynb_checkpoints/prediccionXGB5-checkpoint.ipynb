{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo: XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, nombrefeat, nombretarget):\n",
    "        \n",
    "    temp = train.groupby(nombrefeat)[nombretarget].transform(np.mean) #Saco promedio\n",
    "    temp = preprocessing.scale(temp) #Normalizo\n",
    "    train[nombrefeat] = temp #Dejo en el DF\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41126792,  0.71062843,  0.71062843, ..., -0.41126792,\n",
       "       -0.41126792, -0.41126792])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = train.groupby(\"tipodepropiedad\")[\"precio\"].agg(np.mean) #Saco promedio\n",
    "#temp = preprocessing.scale(temp) #Normalizo\n",
    "#temp\n",
    "#temp_test = test.groupby(\"tipodepropiedad\")[\"tipodepropiedad\"]\n",
    "#.transform(decode, temp = temp, label = \"tipodepropiedad\")\n",
    "temp_test = test['tipodepropiedad'].map(temp)\n",
    "temp_test = preprocessing.scale(temp_test)\n",
    "temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_decoding(test, nombrefeat, nombretarget, train):\n",
    "    \n",
    "    temp = train.groupby(nombrefeat)[nombretarget].agg(np.mean) #Saco promedio\n",
    "    temp_test = test[nombrefeat].map(temp)\n",
    "    temp_test = preprocessing.scale(temp_test)\n",
    "    test[nombrefeat] = temp_test\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mean_target_encoding(train, \"tipodepropiedad\", \"precio\")\n",
    "train = mean_target_encoding(train, \"provincia\", \"precio\")\n",
    "train = mean_target_encoding(train, \"ciudad\", \"precio\")\n",
    "\n",
    "#Adiciono servicios\n",
    "train['servicios'] = train['piscina'] + train['gimnasio'] + train['usosmultiples']\n",
    "\n",
    "#Adiciono cercanias\n",
    "train['ubicacion'] = train['escuelascercanas'] + train['centroscomercialescercanos']\n",
    "\n",
    "#Elimino los residuos\n",
    "train = train.drop(['piscina', 'gimnasio','usosmultiples','escuelascercanas', \n",
    "                      'centroscomercialescercanos'], axis = 1)\n",
    "\n",
    "#Armo mi nuevo train\n",
    "trainXGB = train.drop(['descripcion', 'titulo', 'direccion', 'fecha'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/lorenzo/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6900510179471959,\n",
       "             eval_metric='mae', gamma=0.11042626041444276,\n",
       "             importance_type='gain', learning_rate=0.036505998002060044,\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1, missing=None,\n",
       "             n_estimators=400, n_jobs=1, nthread=None,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=0.6194353865754738, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = trainXGB.drop(['precio'], axis = 1) \n",
    "y_train = trainXGB['precio']\n",
    "\n",
    "#Armo modelo\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
    "                             colsample_bytree = 0.6900510179471959,\n",
    "                             gamma = 0.11042626041444276,\n",
    "                             learning_rate = 0.036505998002060044,\n",
    "                             max_depth = 12,\n",
    "                             n_estimators = 400,\n",
    "                             subsample = 0.6194353865754738,\n",
    "                             eval_metric = \"mae\") #Que es la que se usa en la competencia\n",
    "\n",
    "#Fitteo\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparo TEST\n",
    "trainoriginal = pd.read_csv(\"train.csv\")\n",
    "test = mean_target_decoding(test, \"tipodepropiedad\", \"precio\", trainoriginal)\n",
    "test = mean_target_decoding(test, \"provincia\", \"precio\", trainoriginal)\n",
    "test = mean_target_decoding(test, \"ciudad\", \"precio\", trainoriginal)\n",
    "\n",
    "#Adiciono servicios\n",
    "test['servicios'] = test['piscina'] + test['gimnasio'] + test['usosmultiples']\n",
    "\n",
    "#Adiciono cercanias\n",
    "test['ubicacion'] = test['escuelascercanas'] + test['centroscomercialescercanos']\n",
    "\n",
    "#Elimino los residuos\n",
    "test = test.drop(['piscina', 'gimnasio','usosmultiples','escuelascercanas', 'fecha',\n",
    "                  'centroscomercialescercanos', 'titulo', 'direccion', 'descripcion'], axis = 1)\n",
    "\n",
    "#Predigo\n",
    "prediccion = xgb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = test.loc[:, ['id','ciudad']]\n",
    "predicciones.rename(columns = {'ciudad' : 'target'}, inplace = True)\n",
    "predicciones['target'] = prediccion\n",
    "predicciones = predicciones.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv(r'prediccionXGB4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
