{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> VERSION 1 </b>\n",
    "\n",
    "\n",
    "##### La idea es ahora a partir de los temas vistos en clase poder hacer feature engineering de una manera mas objetiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asi voy a dividir entre train y test para mi validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi_split (df):\n",
    "\n",
    "    X = df.drop(['precio'], axis = 1)\n",
    "    Y = df['precio']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# x_train y_train son mi TRAIN\n",
    "# x_test y_test son mi VALIDACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ................................................................................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Modelo N°1 - XGBoost </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para sacar provecho a las labels provincia, tipodepropiedad y ciudad usaré algún tipo de Mean Target Encoding (basado en el promedio del precio para cada grupo de valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, nombrefeat, nombretarget):\n",
    "        \n",
    "    temp = train.groupby(nombrefeat)[nombretarget].transform(np.mean) #Saco promedio\n",
    "    temp = preprocessing.scale(temp) #Normalizo\n",
    "    train[nombrefeat + \"_mean\"] = temp #Dejo en el DF\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_decoding(x_test, nombrefeat, x_train):\n",
    "    \n",
    "    #temp = x_train.loc[:,[nombrefeat,nombrefeat+\"_mean\"]]\n",
    "    #test = pd.merge(test, temp, on = nombrefeat, how='inner', indicator = True)\n",
    "    #temp = temp.set_index(nombrefeat)\n",
    "    #temp = temp.drop_duplicates()\n",
    "    #temp = temp.T.squeeze()\n",
    "  #  values = test[nombrefeat].map(temp)\n",
    "  #  test[nombrefeat+\"_mean\"] = values\n",
    "    \n",
    "    nombrefeatmean = nombrefeat + \"_mean\"\n",
    "    \n",
    "    temp = x_train.loc[:,[nombrefeat,nombrefeatmean]]\n",
    "    temp = temp.set_index(nombrefeat)\n",
    "    temp = temp.drop_duplicates()\n",
    "    temp = temp.T.squeeze()\n",
    "    values = x_test[nombrefeat].map(temp)\n",
    "    x_test[nombrefeatmean] = values \n",
    "\n",
    "\n",
    "# \"\"   temp = train.groupby(nombrefeat)[nombretarget].agg(np.mean) #Saco promedio\n",
    "#    temp_test = test[nombrefeat].map(temp)\n",
    "#    temp_test = preprocessing.scale(temp_test)\n",
    "#    test[nombrefeat+\"_mean\"] = temp_test\n",
    "\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armar_set(train):\n",
    "    \n",
    "    #Puedo resolver de forma general las que son iguales para train y test\n",
    "    #es decir, aquellas que no filtran informacion a los de validacion\n",
    "    \n",
    "    train = train.drop(['descripcion', 'titulo', 'direccion', 'fecha'], axis = 1)\n",
    "    \n",
    "    train['servicios'] = train['piscina'] + train['gimnasio'] + train['usosmultiples']\n",
    "    \n",
    "    #Elimino los residuos\n",
    "    train = train.drop(['piscina', 'gimnasio','usosmultiples','escuelascercanas', \n",
    "                        'centroscomercialescercanos'], axis = 1)\n",
    "    \n",
    "    #Hago el split                    \n",
    "    x_train, x_test, y_train, y_test = mi_split(train)\n",
    "        \n",
    "    x_train[\"precio\"] = y_train\n",
    "\n",
    "    temporal = x_train\n",
    "    \n",
    "    #Calculo los mean target\n",
    "    x_train_mean = mean_target_encoding(x_train, \"tipodepropiedad\", \"precio\")\n",
    "    x_train_mean['precio'] = y_train\n",
    "    x_train_mean = mean_target_encoding(x_train_mean, \"provincia\", \"precio\")\n",
    "    x_train_mean = mean_target_encoding(x_train_mean, \"ciudad\", \"precio\")\n",
    "    x_train_mean.drop(\"precio\", axis=1)\n",
    "    \n",
    "    #Se los asigno a los test (NO LOS CALCULO CON ELLOS!!!!!!)\n",
    "    x_test = mean_target_decoding(x_test, \"tipodepropiedad\", temporal)\n",
    "    x_test = mean_target_decoding(x_test, \"provincia\", temporal)\n",
    "    x_test = mean_target_decoding(x_test, \"ciudad\", temporal)\n",
    "    \n",
    "    x_train_mean.drop([\"tipodepropiedad\", \"provincia\", \"ciudad\"], axis=1, inplace = True)\n",
    "    x_test.drop([\"tipodepropiedad\", \"provincia\", \"ciudad\"], axis=1, inplace = True)\n",
    "\n",
    "    \n",
    "    return x_train_mean, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = armar_set(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
